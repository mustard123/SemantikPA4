{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "\n",
    "from pa4_functions import load_data, print_stats, ExractSimpleFeatures, extractSegments, evaluateCV\n",
    "from pa4_functions import evaluateCV_check, printLabelsToFile, printNMostInformative, gridSearchCV\n",
    "\n",
    "def useClassifier(clf, encoder, train_features, train_labels, test_features, do_check, filename):\n",
    "    avg = evaluateCV(clf, encoder, train_features, train_labels)\n",
    "    print(\"Average: %f\" % avg)\n",
    "    \n",
    "    if do_check:\n",
    "        evaluateCV_check(clf, train_features, train_labels)\n",
    "\n",
    "    clf.fit(train_features, train_labels)   \n",
    "    test_label_predicted = clf.predict(test_features)\n",
    "\n",
    "    if filename:\n",
    "        printLabelsToFile(encoder, test_label_predicted, filename)\n",
    "        print(\"printed to \" + '\"' + filename + '\"')\n",
    "###########################################################################################\n",
    "# 2. LOAD DATA\n",
    "###########################################################################################\n",
    "train_data, train_labels = load_data('train.json.txt', verbose=False)\n",
    "test_data, _ = load_data('test.json.txt', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################################\n",
    "# 2. EXTRACT FEATURES and LABELS\n",
    "###########################################################################################\n",
    "# LABELS\n",
    "le = LabelEncoder()\n",
    "train_labels_onehot =le.fit_transform(train_labels)\n",
    "\n",
    "# FEATURES - TRAIN & TEST\n",
    "train_data_featurized = ExractSimpleFeatures(train_data, verbose=False)\n",
    "test_data_featurized = ExractSimpleFeatures(test_data, verbose=False)\n",
    "\n",
    "train_data_middle_segment = extractSegments(train_data, False, True, False)\n",
    "test_data_middle_segment = extractSegments(test_data, False, True, False)\n",
    "\n",
    "train_data_all_segments = extractSegments(train_data, True, True, True)\n",
    "test_data_all_segments = extractSegments(test_data, True, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################################\n",
    "# 3. BUILD PIPELINES\n",
    "###########################################################################################\n",
    "# best old pipeline\n",
    "# clf3 = make_pipeline(TfidfVectorizer(ngram_range=(0, 3), analyzer='char'), LogisticRegression())\n",
    "\n",
    "#clf1 gives the same results as Tatyana's pipe \n",
    "clf1 = make_pipeline(CountVectorizer(), LogisticRegression())\n",
    "clf2 = make_pipeline(TfidfVectorizer(), LogisticRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization with GridSearch\n",
    "Here, the hyperparameters of the classifiers are optimized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CountVectorizer and Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relation              precision     recall    f-score    support\n",
      "------------------    ---------  ---------  ---------  ---------\n",
      "NO_REL                    0.661      0.714      0.671       2300\n",
      "author                    0.815      0.813      0.814       2653\n",
      "capital                   0.883      0.639      0.820        510\n",
      "has_spouse                0.860      0.902      0.868       3019\n",
      "worked_at                 0.727      0.611      0.700       1178\n",
      "------------------    ---------  ---------  ---------  ---------\n",
      "macro-average             0.789      0.736      0.775       9660\n",
      "Average: 0.774663\n",
      "\n",
      "Cross-validation scores (StratifiedKFold):  [0.77310582 0.77412754 0.77655771 0.77941565 0.77010789]\n",
      "Mean cv score (StratifiedKFold):  0.7746629212275845\n"
     ]
    }
   ],
   "source": [
    "# This is the initial performance of the classifier\n",
    "clf1 = make_pipeline(CountVectorizer(), LogisticRegression())\n",
    "useClassifier(clf1, le, train_data_all_segments, train_labels_onehot, test_data_all_segments, False, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV] countvectorizer__analyzer=word, countvectorizer__ngram_range=(1, 1) \n",
      "[CV]  countvectorizer__analyzer=word, countvectorizer__ngram_range=(1, 1), total=   2.0s\n",
      "[CV] countvectorizer__analyzer=word, countvectorizer__ngram_range=(1, 1) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  countvectorizer__analyzer=word, countvectorizer__ngram_range=(1, 1), total=   2.4s\n",
      "[CV] countvectorizer__analyzer=word, countvectorizer__ngram_range=(1, 1) \n",
      "[CV]  countvectorizer__analyzer=word, countvectorizer__ngram_range=(1, 1), total=   2.4s\n",
      "[CV] countvectorizer__analyzer=word, countvectorizer__ngram_range=(1, 1) \n",
      "[CV]  countvectorizer__analyzer=word, countvectorizer__ngram_range=(1, 1), total=   1.9s\n",
      "[CV] countvectorizer__analyzer=word, countvectorizer__ngram_range=(1, 1) \n",
      "[CV]  countvectorizer__analyzer=word, countvectorizer__ngram_range=(1, 1), total=   1.7s\n",
      "[CV] countvectorizer__analyzer=word, countvectorizer__ngram_range=(1, 2) \n",
      "[CV]  countvectorizer__analyzer=word, countvectorizer__ngram_range=(1, 2), total=   3.6s\n",
      "[CV] countvectorizer__analyzer=word, countvectorizer__ngram_range=(1, 2) \n",
      "[CV]  countvectorizer__analyzer=word, countvectorizer__ngram_range=(1, 2), total=   4.6s\n",
      "[CV] countvectorizer__analyzer=word, countvectorizer__ngram_range=(1, 2) \n",
      "[CV]  countvectorizer__analyzer=word, countvectorizer__ngram_range=(1, 2), total=   2.2s\n",
      "[CV] countvectorizer__analyzer=word, countvectorizer__ngram_range=(1, 2) \n",
      "[CV]  countvectorizer__analyzer=word, countvectorizer__ngram_range=(1, 2), total=   4.5s\n",
      "[CV] countvectorizer__analyzer=word, countvectorizer__ngram_range=(1, 2) \n",
      "[CV]  countvectorizer__analyzer=word, countvectorizer__ngram_range=(1, 2), total=   2.0s\n",
      "[CV] countvectorizer__analyzer=word, countvectorizer__ngram_range=(2, 2) \n",
      "[CV]  countvectorizer__analyzer=word, countvectorizer__ngram_range=(2, 2), total=   2.1s\n",
      "[CV] countvectorizer__analyzer=word, countvectorizer__ngram_range=(2, 2) \n",
      "[CV]  countvectorizer__analyzer=word, countvectorizer__ngram_range=(2, 2), total=   3.2s\n",
      "[CV] countvectorizer__analyzer=word, countvectorizer__ngram_range=(2, 2) \n",
      "[CV]  countvectorizer__analyzer=word, countvectorizer__ngram_range=(2, 2), total=   3.1s\n",
      "[CV] countvectorizer__analyzer=word, countvectorizer__ngram_range=(2, 2) \n",
      "[CV]  countvectorizer__analyzer=word, countvectorizer__ngram_range=(2, 2), total=   3.7s\n",
      "[CV] countvectorizer__analyzer=word, countvectorizer__ngram_range=(2, 2) \n",
      "[CV]  countvectorizer__analyzer=word, countvectorizer__ngram_range=(2, 2), total=   5.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:   55.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: \n",
      "0.762 (+/-0.014) for {'countvectorizer__analyzer': 'word', 'countvectorizer__ngram_range': (1, 2)}\n",
      "\n",
      "Grid: \n",
      "0.757 (+/-0.013) for {'countvectorizer__analyzer': 'word', 'countvectorizer__ngram_range': (1, 1)}\n",
      "0.762 (+/-0.014) for {'countvectorizer__analyzer': 'word', 'countvectorizer__ngram_range': (1, 2)}\n",
      "0.736 (+/-0.022) for {'countvectorizer__analyzer': 'word', 'countvectorizer__ngram_range': (2, 2)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'countvectorizer__analyzer': 'word', 'countvectorizer__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the first gridsearch: the result seems to say, that 1-2 grams are best for this task\n",
    "parameters = {\n",
    "    'countvectorizer__analyzer': ['word', ],#'char'],\n",
    "    'countvectorizer__stop_words': ['english', None],\n",
    "    'countvectorizer__ngram_range': [(1, 1), (1, 2), (2, 2)], \n",
    "}\n",
    "clf1 = make_pipeline(CountVectorizer(), LogisticRegression())\n",
    "gridSearchCV(clf1, parameters, train_data_middle_segment, train_labels_onehot, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV] logisticregression__multi_class=ovr, logisticregression__penalty=l2, logisticregression__solver=lbfgs \n",
      "[CV]  logisticregression__multi_class=ovr, logisticregression__penalty=l2, logisticregression__solver=lbfgs, total=  10.2s\n",
      "[CV] logisticregression__multi_class=ovr, logisticregression__penalty=l2, logisticregression__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   10.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  logisticregression__multi_class=ovr, logisticregression__penalty=l2, logisticregression__solver=lbfgs, total=  10.0s\n",
      "[CV] logisticregression__multi_class=ovr, logisticregression__penalty=l2, logisticregression__solver=lbfgs \n",
      "[CV]  logisticregression__multi_class=ovr, logisticregression__penalty=l2, logisticregression__solver=lbfgs, total=  10.1s\n",
      "[CV] logisticregression__multi_class=ovr, logisticregression__penalty=l2, logisticregression__solver=lbfgs \n",
      "[CV]  logisticregression__multi_class=ovr, logisticregression__penalty=l2, logisticregression__solver=lbfgs, total=   8.9s\n",
      "[CV] logisticregression__multi_class=ovr, logisticregression__penalty=l2, logisticregression__solver=lbfgs \n",
      "[CV]  logisticregression__multi_class=ovr, logisticregression__penalty=l2, logisticregression__solver=lbfgs, total=   8.3s\n",
      "[CV] logisticregression__multi_class=ovr, logisticregression__penalty=l2, logisticregression__solver=newton-cg \n",
      "[CV]  logisticregression__multi_class=ovr, logisticregression__penalty=l2, logisticregression__solver=newton-cg, total=   7.6s\n",
      "[CV] logisticregression__multi_class=ovr, logisticregression__penalty=l2, logisticregression__solver=newton-cg \n",
      "[CV]  logisticregression__multi_class=ovr, logisticregression__penalty=l2, logisticregression__solver=newton-cg, total=   7.6s\n",
      "[CV] logisticregression__multi_class=ovr, logisticregression__penalty=l2, logisticregression__solver=newton-cg \n",
      "[CV]  logisticregression__multi_class=ovr, logisticregression__penalty=l2, logisticregression__solver=newton-cg, total=   8.3s\n",
      "[CV] logisticregression__multi_class=ovr, logisticregression__penalty=l2, logisticregression__solver=newton-cg \n",
      "[CV]  logisticregression__multi_class=ovr, logisticregression__penalty=l2, logisticregression__solver=newton-cg, total=   9.7s\n",
      "[CV] logisticregression__multi_class=ovr, logisticregression__penalty=l2, logisticregression__solver=newton-cg \n",
      "[CV]  logisticregression__multi_class=ovr, logisticregression__penalty=l2, logisticregression__solver=newton-cg, total=  10.4s\n",
      "[CV] logisticregression__multi_class=ovr, logisticregression__penalty=l2, logisticregression__solver=sag \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  logisticregression__multi_class=ovr, logisticregression__penalty=l2, logisticregression__solver=sag, total=  16.7s\n",
      "[CV] logisticregression__multi_class=ovr, logisticregression__penalty=l2, logisticregression__solver=sag \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  logisticregression__multi_class=ovr, logisticregression__penalty=l2, logisticregression__solver=sag, total=  19.6s\n",
      "[CV] logisticregression__multi_class=ovr, logisticregression__penalty=l2, logisticregression__solver=sag \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  logisticregression__multi_class=ovr, logisticregression__penalty=l2, logisticregression__solver=sag, total=  16.7s\n",
      "[CV] logisticregression__multi_class=ovr, logisticregression__penalty=l2, logisticregression__solver=sag \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  logisticregression__multi_class=ovr, logisticregression__penalty=l2, logisticregression__solver=sag, total=  18.9s\n",
      "[CV] logisticregression__multi_class=ovr, logisticregression__penalty=l2, logisticregression__solver=sag \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  logisticregression__multi_class=ovr, logisticregression__penalty=l2, logisticregression__solver=sag, total=  18.6s\n",
      "[CV] logisticregression__multi_class=multinomial, logisticregression__penalty=l2, logisticregression__solver=lbfgs \n",
      "[CV]  logisticregression__multi_class=multinomial, logisticregression__penalty=l2, logisticregression__solver=lbfgs, total=  16.2s\n",
      "[CV] logisticregression__multi_class=multinomial, logisticregression__penalty=l2, logisticregression__solver=lbfgs \n",
      "[CV]  logisticregression__multi_class=multinomial, logisticregression__penalty=l2, logisticregression__solver=lbfgs, total=  10.9s\n",
      "[CV] logisticregression__multi_class=multinomial, logisticregression__penalty=l2, logisticregression__solver=lbfgs \n",
      "[CV]  logisticregression__multi_class=multinomial, logisticregression__penalty=l2, logisticregression__solver=lbfgs, total=  12.2s\n",
      "[CV] logisticregression__multi_class=multinomial, logisticregression__penalty=l2, logisticregression__solver=lbfgs \n",
      "[CV]  logisticregression__multi_class=multinomial, logisticregression__penalty=l2, logisticregression__solver=lbfgs, total=  13.3s\n",
      "[CV] logisticregression__multi_class=multinomial, logisticregression__penalty=l2, logisticregression__solver=lbfgs \n",
      "[CV]  logisticregression__multi_class=multinomial, logisticregression__penalty=l2, logisticregression__solver=lbfgs, total=  13.5s\n",
      "[CV] logisticregression__multi_class=multinomial, logisticregression__penalty=l2, logisticregression__solver=newton-cg \n",
      "[CV]  logisticregression__multi_class=multinomial, logisticregression__penalty=l2, logisticregression__solver=newton-cg, total=  18.9s\n",
      "[CV] logisticregression__multi_class=multinomial, logisticregression__penalty=l2, logisticregression__solver=newton-cg \n",
      "[CV]  logisticregression__multi_class=multinomial, logisticregression__penalty=l2, logisticregression__solver=newton-cg, total=  17.5s\n",
      "[CV] logisticregression__multi_class=multinomial, logisticregression__penalty=l2, logisticregression__solver=newton-cg \n",
      "[CV]  logisticregression__multi_class=multinomial, logisticregression__penalty=l2, logisticregression__solver=newton-cg, total=  20.8s\n",
      "[CV] logisticregression__multi_class=multinomial, logisticregression__penalty=l2, logisticregression__solver=newton-cg \n",
      "[CV]  logisticregression__multi_class=multinomial, logisticregression__penalty=l2, logisticregression__solver=newton-cg, total=  15.3s\n",
      "[CV] logisticregression__multi_class=multinomial, logisticregression__penalty=l2, logisticregression__solver=newton-cg \n",
      "[CV]  logisticregression__multi_class=multinomial, logisticregression__penalty=l2, logisticregression__solver=newton-cg, total=  13.8s\n",
      "[CV] logisticregression__multi_class=multinomial, logisticregression__penalty=l2, logisticregression__solver=sag \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  logisticregression__multi_class=multinomial, logisticregression__penalty=l2, logisticregression__solver=sag, total=   8.5s\n",
      "[CV] logisticregression__multi_class=multinomial, logisticregression__penalty=l2, logisticregression__solver=sag \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  logisticregression__multi_class=multinomial, logisticregression__penalty=l2, logisticregression__solver=sag, total=  10.8s\n",
      "[CV] logisticregression__multi_class=multinomial, logisticregression__penalty=l2, logisticregression__solver=sag \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  logisticregression__multi_class=multinomial, logisticregression__penalty=l2, logisticregression__solver=sag, total=   5.9s\n",
      "[CV] logisticregression__multi_class=multinomial, logisticregression__penalty=l2, logisticregression__solver=sag \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  logisticregression__multi_class=multinomial, logisticregression__penalty=l2, logisticregression__solver=sag, total=  11.5s\n",
      "[CV] logisticregression__multi_class=multinomial, logisticregression__penalty=l2, logisticregression__solver=sag \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  logisticregression__multi_class=multinomial, logisticregression__penalty=l2, logisticregression__solver=sag, total=   9.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  6.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: \n",
      "0.763 (+/-0.014) for {'logisticregression__multi_class': 'ovr', 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'lbfgs'}\n",
      "\n",
      "Grid: \n",
      "0.763 (+/-0.014) for {'logisticregression__multi_class': 'ovr', 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'lbfgs'}\n",
      "0.763 (+/-0.014) for {'logisticregression__multi_class': 'ovr', 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'newton-cg'}\n",
      "0.672 (+/-0.034) for {'logisticregression__multi_class': 'ovr', 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'sag'}\n",
      "0.758 (+/-0.016) for {'logisticregression__multi_class': 'multinomial', 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'lbfgs'}\n",
      "0.758 (+/-0.016) for {'logisticregression__multi_class': 'multinomial', 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'newton-cg'}\n",
      "0.691 (+/-0.043) for {'logisticregression__multi_class': 'multinomial', 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'sag'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'logisticregression__multi_class': 'ovr',\n",
       " 'logisticregression__penalty': 'l2',\n",
       " 'logisticregression__solver': 'lbfgs'}"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters2 = {\n",
    "    #'logisticregression__C': [1, 10, 100, 1000],\n",
    "    'logisticregression__penalty':['l2'],\n",
    "    'logisticregression__solver':['lbfgs', 'newton-cg', 'sag'], # only with l2 penalty\n",
    "    'logisticregression__multi_class':['ovr', 'multinomial'], # multinomial not for solver=’liblinear’\n",
    "    # n_jobs can be set for multi_class = ovr, but then solver cannot be liblinear\n",
    "}\n",
    "clf1 = make_pipeline(CountVectorizer(ngram_range=(1, 2)), LogisticRegression())\n",
    "gridSearchCV(clf1, parameters2, train_data_middle_segment, train_labels_onehot, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relation              precision     recall    f-score    support\n",
      "------------------    ---------  ---------  ---------  ---------\n",
      "NO_REL                    0.665      0.719      0.675       2300\n",
      "author                    0.817      0.815      0.816       2653\n",
      "capital                   0.879      0.645      0.819        510\n",
      "has_spouse                0.862      0.902      0.869       3019\n",
      "worked_at                 0.729      0.610      0.701       1178\n",
      "------------------    ---------  ---------  ---------  ---------\n",
      "macro-average             0.790      0.738      0.776       9660\n",
      "Average: 0.776135\n",
      "\n",
      "Cross-validation scores (StratifiedKFold):  [0.76938566 0.77412185 0.78397105 0.78192044 0.77127563]\n",
      "Mean cv score (StratifiedKFold):  0.7761349285160714\n"
     ]
    }
   ],
   "source": [
    "clf2mod = make_pipeline(CountVectorizer(), LogisticRegression(multi_class='ovr', solver='lbfgs'))\n",
    "useClassifier(clf2mod, le, train_data_all_segments, train_labels_onehot, test_data_all_segments, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relation              precision     recall    f-score    support\n",
      "------------------    ---------  ---------  ---------  ---------\n",
      "NO_REL                    0.656      0.780      0.677       2300\n",
      "author                    0.836      0.826      0.834       2653\n",
      "capital                   0.932      0.657      0.859        510\n",
      "has_spouse                0.893      0.909      0.896       3019\n",
      "worked_at                 0.790      0.587      0.739       1178\n",
      "------------------    ---------  ---------  ---------  ---------\n",
      "macro-average             0.822      0.751      0.801       9660\n",
      "Average: 0.801213\n",
      "\n",
      "Cross-validation scores (StratifiedKFold):  [0.79292147 0.80051931 0.8116933  0.80162961 0.79930227]\n",
      "Mean cv score (StratifiedKFold):  0.801213192485917\n"
     ]
    }
   ],
   "source": [
    "clf2mod = make_pipeline(CountVectorizer(ngram_range=(1, 2)), LogisticRegression(multi_class='ovr', solver='lbfgs'))\n",
    "useClassifier(clf2mod, le, train_data_all_segments, train_labels_onehot, test_data_all_segments, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TfidfVectorizer and Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters0 = {\n",
    "    'tfidfvectorizer__analyzer': ['char'], #['word', 'char'],\n",
    "    'tfidfvectorizer__stop_words': ['english', None],\n",
    "    'tfidfvectorizer__ngram_range': [(1, 2), (1, 3), (2, 3)],\n",
    "    #'tfidfvectorizer__use_idf': [True, False],\n",
    "    #'tfidfvectorizer__max_df': [0.1, 0.5, 1.0],\n",
    "    #'tfidfvectorizer__min_df': [1, 5, 10],    \n",
    "}\n",
    "parameters1 = {\n",
    "    'logisticregression__C': [0.1, 1, 10],\n",
    "    'logisticregression__penalty':['l2'], # 'l1',  always seems to be worse\n",
    "    'logisticregression__solver':['liblinear'], # , 'saga' does not seem to converge\n",
    "    #'logisticregression__dual':[True, False], # can only be true for l2 penalty with liblinear solver\n",
    "}\n",
    "parameters2 = {\n",
    "    #'logisticregression__C': [1, 10, 100, 1000],\n",
    "    'logisticregression__penalty':['l2'],\n",
    "    'logisticregression__solver':['lbfgs', 'newton-cg', 'sag'], # only with l2 penalty\n",
    "    'logisticregression__multi_class':['ovr', 'multinomial'], # multinomial not for solver=’liblinear’\n",
    "    # n_jobs can be set for multi_class = ovr, but then solver cannot be liblinear\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV] tfidfvectorizer__analyzer=char, tfidfvectorizer__ngram_range=(1, 2), tfidfvectorizer__stop_words=english \n",
      "[CV]  tfidfvectorizer__analyzer=char, tfidfvectorizer__ngram_range=(1, 2), tfidfvectorizer__stop_words=english, total=   4.3s\n",
      "[CV] tfidfvectorizer__analyzer=char, tfidfvectorizer__ngram_range=(1, 2), tfidfvectorizer__stop_words=english \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  tfidfvectorizer__analyzer=char, tfidfvectorizer__ngram_range=(1, 2), tfidfvectorizer__stop_words=english, total=   3.3s\n",
      "[CV] tfidfvectorizer__analyzer=char, tfidfvectorizer__ngram_range=(1, 2), tfidfvectorizer__stop_words=english \n",
      "[CV]  tfidfvectorizer__analyzer=char, tfidfvectorizer__ngram_range=(1, 2), tfidfvectorizer__stop_words=english, total=   4.4s\n",
      "[CV] tfidfvectorizer__analyzer=char, tfidfvectorizer__ngram_range=(1, 2), tfidfvectorizer__stop_words=english \n",
      "[CV]  tfidfvectorizer__analyzer=char, tfidfvectorizer__ngram_range=(1, 2), tfidfvectorizer__stop_words=english, total=   3.0s\n",
      "[CV] tfidfvectorizer__analyzer=char, tfidfvectorizer__ngram_range=(1, 2), tfidfvectorizer__stop_words=english \n",
      "[CV]  tfidfvectorizer__analyzer=char, tfidfvectorizer__ngram_range=(1, 2), tfidfvectorizer__stop_words=english, total=   2.8s\n",
      "[CV] tfidfvectorizer__analyzer=char, tfidfvectorizer__ngram_range=(1, 2), tfidfvectorizer__stop_words=None \n",
      "[CV]  tfidfvectorizer__analyzer=char, tfidfvectorizer__ngram_range=(1, 2), tfidfvectorizer__stop_words=None, total=   2.8s\n",
      "[CV] tfidfvectorizer__analyzer=char, tfidfvectorizer__ngram_range=(1, 2), tfidfvectorizer__stop_words=None \n",
      "[CV]  tfidfvectorizer__analyzer=char, tfidfvectorizer__ngram_range=(1, 2), tfidfvectorizer__stop_words=None, total=   2.7s\n",
      "[CV] tfidfvectorizer__analyzer=char, tfidfvectorizer__ngram_range=(1, 2), tfidfvectorizer__stop_words=None \n",
      "[CV]  tfidfvectorizer__analyzer=char, tfidfvectorizer__ngram_range=(1, 2), tfidfvectorizer__stop_words=None, total=   2.8s\n",
      "[CV] tfidfvectorizer__analyzer=char, tfidfvectorizer__ngram_range=(1, 2), tfidfvectorizer__stop_words=None \n",
      "[CV]  tfidfvectorizer__analyzer=char, tfidfvectorizer__ngram_range=(1, 2), tfidfvectorizer__stop_words=None, total=   2.8s\n",
      "[CV] tfidfvectorizer__analyzer=char, tfidfvectorizer__ngram_range=(1, 2), tfidfvectorizer__stop_words=None \n",
      "[CV]  tfidfvectorizer__analyzer=char, tfidfvectorizer__ngram_range=(1, 2), tfidfvectorizer__stop_words=None, total=   4.2s\n",
      "[CV] tfidfvectorizer__analyzer=char, tfidfvectorizer__ngram_range=(1, 3), tfidfvectorizer__stop_words=english \n",
      "[CV]  tfidfvectorizer__analyzer=char, tfidfvectorizer__ngram_range=(1, 3), tfidfvectorizer__stop_words=english, total=   5.3s\n",
      "[CV] tfidfvectorizer__analyzer=char, tfidfvectorizer__ngram_range=(1, 3), tfidfvectorizer__stop_words=english \n",
      "[CV]  tfidfvectorizer__analyzer=char, tfidfvectorizer__ngram_range=(1, 3), tfidfvectorizer__stop_words=english, total=   5.1s\n",
      "[CV] tfidfvectorizer__analyzer=char, tfidfvectorizer__ngram_range=(1, 3), tfidfvectorizer__stop_words=english \n",
      "[CV]  tfidfvectorizer__analyzer=char, tfidfvectorizer__ngram_range=(1, 3), tfidfvectorizer__stop_words=english, total=   4.5s\n",
      "[CV] tfidfvectorizer__analyzer=char, tfidfvectorizer__ngram_range=(1, 3), tfidfvectorizer__stop_words=english \n",
      "[CV]  tfidfvectorizer__analyzer=char, tfidfvectorizer__ngram_range=(1, 3), tfidfvectorizer__stop_words=english, total=   5.8s\n",
      "[CV] tfidfvectorizer__analyzer=char, tfidfvectorizer__ngram_range=(1, 3), tfidfvectorizer__stop_words=english \n",
      "[CV]  tfidfvectorizer__analyzer=char, tfidfvectorizer__ngram_range=(1, 3), tfidfvectorizer__stop_words=english, total=   6.5s\n",
      "[CV] tfidfvectorizer__analyzer=char, tfidfvectorizer__ngram_range=(1, 3), tfidfvectorizer__stop_words=None \n",
      "[CV]  tfidfvectorizer__analyzer=char, tfidfvectorizer__ngram_range=(1, 3), tfidfvectorizer__stop_words=None, total=   6.5s\n",
      "[CV] tfidfvectorizer__analyzer=char, tfidfvectorizer__ngram_range=(1, 3), tfidfvectorizer__stop_words=None \n",
      "[CV]  tfidfvectorizer__analyzer=char, tfidfvectorizer__ngram_range=(1, 3), tfidfvectorizer__stop_words=None, total=   5.8s\n",
      "[CV] tfidfvectorizer__analyzer=char, tfidfvectorizer__ngram_range=(1, 3), tfidfvectorizer__stop_words=None \n",
      "[CV]  tfidfvectorizer__analyzer=char, tfidfvectorizer__ngram_range=(1, 3), tfidfvectorizer__stop_words=None, total=   6.8s\n",
      "[CV] tfidfvectorizer__analyzer=char, tfidfvectorizer__ngram_range=(1, 3), tfidfvectorizer__stop_words=None \n",
      "[CV]  tfidfvectorizer__analyzer=char, tfidfvectorizer__ngram_range=(1, 3), tfidfvectorizer__stop_words=None, total=   6.3s\n",
      "[CV] tfidfvectorizer__analyzer=char, tfidfvectorizer__ngram_range=(1, 3), tfidfvectorizer__stop_words=None \n",
      "[CV]  tfidfvectorizer__analyzer=char, tfidfvectorizer__ngram_range=(1, 3), tfidfvectorizer__stop_words=None, total=   6.7s\n",
      "[CV] tfidfvectorizer__analyzer=char, tfidfvectorizer__ngram_range=(2, 3), tfidfvectorizer__stop_words=english \n",
      "[CV]  tfidfvectorizer__analyzer=char, tfidfvectorizer__ngram_range=(2, 3), tfidfvectorizer__stop_words=english, total=   5.5s\n",
      "[CV] tfidfvectorizer__analyzer=char, tfidfvectorizer__ngram_range=(2, 3), tfidfvectorizer__stop_words=english \n",
      "[CV]  tfidfvectorizer__analyzer=char, tfidfvectorizer__ngram_range=(2, 3), tfidfvectorizer__stop_words=english, total=   5.2s\n",
      "[CV] tfidfvectorizer__analyzer=char, tfidfvectorizer__ngram_range=(2, 3), tfidfvectorizer__stop_words=english \n",
      "[CV]  tfidfvectorizer__analyzer=char, tfidfvectorizer__ngram_range=(2, 3), tfidfvectorizer__stop_words=english, total=   5.1s\n",
      "[CV] tfidfvectorizer__analyzer=char, tfidfvectorizer__ngram_range=(2, 3), tfidfvectorizer__stop_words=english \n",
      "[CV]  tfidfvectorizer__analyzer=char, tfidfvectorizer__ngram_range=(2, 3), tfidfvectorizer__stop_words=english, total=   4.7s\n",
      "[CV] tfidfvectorizer__analyzer=char, tfidfvectorizer__ngram_range=(2, 3), tfidfvectorizer__stop_words=english \n",
      "[CV]  tfidfvectorizer__analyzer=char, tfidfvectorizer__ngram_range=(2, 3), tfidfvectorizer__stop_words=english, total=   5.1s\n",
      "[CV] tfidfvectorizer__analyzer=char, tfidfvectorizer__ngram_range=(2, 3), tfidfvectorizer__stop_words=None \n",
      "[CV]  tfidfvectorizer__analyzer=char, tfidfvectorizer__ngram_range=(2, 3), tfidfvectorizer__stop_words=None, total=   5.8s\n",
      "[CV] tfidfvectorizer__analyzer=char, tfidfvectorizer__ngram_range=(2, 3), tfidfvectorizer__stop_words=None \n",
      "[CV]  tfidfvectorizer__analyzer=char, tfidfvectorizer__ngram_range=(2, 3), tfidfvectorizer__stop_words=None, total=   5.6s\n",
      "[CV] tfidfvectorizer__analyzer=char, tfidfvectorizer__ngram_range=(2, 3), tfidfvectorizer__stop_words=None \n",
      "[CV]  tfidfvectorizer__analyzer=char, tfidfvectorizer__ngram_range=(2, 3), tfidfvectorizer__stop_words=None, total=   5.0s\n",
      "[CV] tfidfvectorizer__analyzer=char, tfidfvectorizer__ngram_range=(2, 3), tfidfvectorizer__stop_words=None \n",
      "[CV]  tfidfvectorizer__analyzer=char, tfidfvectorizer__ngram_range=(2, 3), tfidfvectorizer__stop_words=None, total=   5.4s\n",
      "[CV] tfidfvectorizer__analyzer=char, tfidfvectorizer__ngram_range=(2, 3), tfidfvectorizer__stop_words=None \n",
      "[CV]  tfidfvectorizer__analyzer=char, tfidfvectorizer__ngram_range=(2, 3), tfidfvectorizer__stop_words=None, total=   5.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  3.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: \n",
      "0.782 (+/-0.010) for {'tfidfvectorizer__analyzer': 'char', 'tfidfvectorizer__ngram_range': (2, 3), 'tfidfvectorizer__stop_words': 'english'}\n",
      "\n",
      "Grid: \n",
      "0.748 (+/-0.009) for {'tfidfvectorizer__analyzer': 'char', 'tfidfvectorizer__ngram_range': (1, 2), 'tfidfvectorizer__stop_words': 'english'}\n",
      "0.748 (+/-0.009) for {'tfidfvectorizer__analyzer': 'char', 'tfidfvectorizer__ngram_range': (1, 2), 'tfidfvectorizer__stop_words': None}\n",
      "0.780 (+/-0.010) for {'tfidfvectorizer__analyzer': 'char', 'tfidfvectorizer__ngram_range': (1, 3), 'tfidfvectorizer__stop_words': 'english'}\n",
      "0.780 (+/-0.010) for {'tfidfvectorizer__analyzer': 'char', 'tfidfvectorizer__ngram_range': (1, 3), 'tfidfvectorizer__stop_words': None}\n",
      "0.782 (+/-0.010) for {'tfidfvectorizer__analyzer': 'char', 'tfidfvectorizer__ngram_range': (2, 3), 'tfidfvectorizer__stop_words': 'english'}\n",
      "0.782 (+/-0.010) for {'tfidfvectorizer__analyzer': 'char', 'tfidfvectorizer__ngram_range': (2, 3), 'tfidfvectorizer__stop_words': None}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'tfidfvectorizer__analyzer': 'char',\n",
       " 'tfidfvectorizer__ngram_range': (2, 3),\n",
       " 'tfidfvectorizer__stop_words': 'english'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridSearchCV(clf2, parameters0, train_data_middle_segment, train_labels_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relation              precision     recall    f-score    support\n",
      "------------------    ---------  ---------  ---------  ---------\n",
      "NO_REL                    0.598      0.730      0.621       2300\n",
      "author                    0.874      0.850      0.869       2653\n",
      "capital                   0.871      0.620      0.805        510\n",
      "has_spouse                0.852      0.852      0.852       3019\n",
      "worked_at                 0.814      0.609      0.762       1178\n",
      "------------------    ---------  ---------  ---------  ---------\n",
      "macro-average             0.802      0.732      0.782       9660\n",
      "Average: 0.78\n",
      "\n",
      "Cross-validation scores (StratifiedKFold):  [0.76872924 0.78926317 0.81156896 0.77699781 0.76176503]\n",
      "Mean cv score (StratifiedKFold):  0.7816648402230364\n"
     ]
    }
   ],
   "source": [
    "clf2mod = make_pipeline(TfidfVectorizer(stop_words='english', ngram_range=(2, 3), analyzer='char'), LogisticRegression())\n",
    "useClassifier(clf2mod, le, train_data_middle_segment, train_labels_onehot, test_data_middle_segment, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "[CV] logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=liblinear \n",
      "[CV]  logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=liblinear, total=   3.9s\n",
      "[CV] logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=liblinear \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=liblinear, total=   3.8s\n",
      "[CV] logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=liblinear \n",
      "[CV]  logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=liblinear, total=   3.9s\n",
      "[CV] logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=liblinear \n",
      "[CV]  logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=liblinear, total=   5.8s\n",
      "[CV] logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=liblinear \n",
      "[CV]  logisticregression__C=0.1, logisticregression__penalty=l2, logisticregression__solver=liblinear, total=   4.6s\n",
      "[CV] logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=liblinear \n",
      "[CV]  logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=liblinear, total=   5.0s\n",
      "[CV] logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=liblinear \n",
      "[CV]  logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=liblinear, total=   5.3s\n",
      "[CV] logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=liblinear \n",
      "[CV]  logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=liblinear, total=   5.2s\n",
      "[CV] logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=liblinear \n",
      "[CV]  logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=liblinear, total=   4.7s\n",
      "[CV] logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=liblinear \n",
      "[CV]  logisticregression__C=1, logisticregression__penalty=l2, logisticregression__solver=liblinear, total=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: \n",
      "0.782 (+/-0.010) for {'logisticregression__C': 1, 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'liblinear'}\n",
      "\n",
      "Grid: \n",
      "0.741 (+/-0.015) for {'logisticregression__C': 0.1, 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'liblinear'}\n",
      "0.782 (+/-0.010) for {'logisticregression__C': 1, 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'liblinear'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'logisticregression__C': 1,\n",
       " 'logisticregression__penalty': 'l2',\n",
       " 'logisticregression__solver': 'liblinear'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2mod = make_pipeline(TfidfVectorizer(stop_words='english', ngram_range=(2, 3), analyzer='char'), LogisticRegression())\n",
    "gridSearchCV(clf2mod, parameters1, train_data_middle_segment, train_labels_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV] logisticregression__multi_class=ovr, logisticregression__penalty=l2, logisticregression__solver=lbfgs \n",
      "[CV]  logisticregression__multi_class=ovr, logisticregression__penalty=l2, logisticregression__solver=lbfgs, total=   6.2s\n",
      "[CV] logisticregression__multi_class=ovr, logisticregression__penalty=l2, logisticregression__solver=lbfgs \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    8.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  logisticregression__multi_class=ovr, logisticregression__penalty=l2, logisticregression__solver=lbfgs, total=   5.9s\n",
      "[CV] logisticregression__multi_class=ovr, logisticregression__penalty=l2, logisticregression__solver=lbfgs \n",
      "[CV]  logisticregression__multi_class=ovr, logisticregression__penalty=l2, logisticregression__solver=lbfgs, total=   7.3s\n",
      "[CV] logisticregression__multi_class=ovr, logisticregression__penalty=l2, logisticregression__solver=lbfgs \n",
      "[CV]  logisticregression__multi_class=ovr, logisticregression__penalty=l2, logisticregression__solver=lbfgs, total=   7.8s\n",
      "[CV] logisticregression__multi_class=ovr, logisticregression__penalty=l2, logisticregression__solver=lbfgs \n",
      "[CV]  logisticregression__multi_class=ovr, logisticregression__penalty=l2, logisticregression__solver=lbfgs, total=   7.7s\n",
      "[CV] logisticregression__multi_class=ovr, logisticregression__penalty=l2, logisticregression__solver=newton-cg \n",
      "[CV]  logisticregression__multi_class=ovr, logisticregression__penalty=l2, logisticregression__solver=newton-cg, total=   8.4s\n",
      "[CV] logisticregression__multi_class=ovr, logisticregression__penalty=l2, logisticregression__solver=newton-cg \n",
      "[CV]  logisticregression__multi_class=ovr, logisticregression__penalty=l2, logisticregression__solver=newton-cg, total=   6.7s\n",
      "[CV] logisticregression__multi_class=ovr, logisticregression__penalty=l2, logisticregression__solver=newton-cg \n",
      "[CV]  logisticregression__multi_class=ovr, logisticregression__penalty=l2, logisticregression__solver=newton-cg, total=   9.4s\n",
      "[CV] logisticregression__multi_class=ovr, logisticregression__penalty=l2, logisticregression__solver=newton-cg \n",
      "[CV]  logisticregression__multi_class=ovr, logisticregression__penalty=l2, logisticregression__solver=newton-cg, total=   8.5s\n",
      "[CV] logisticregression__multi_class=ovr, logisticregression__penalty=l2, logisticregression__solver=newton-cg \n",
      "[CV]  logisticregression__multi_class=ovr, logisticregression__penalty=l2, logisticregression__solver=newton-cg, total=   8.7s\n",
      "[CV] logisticregression__multi_class=ovr, logisticregression__penalty=l2, logisticregression__solver=sag \n",
      "[CV]  logisticregression__multi_class=ovr, logisticregression__penalty=l2, logisticregression__solver=sag, total=   5.7s\n",
      "[CV] logisticregression__multi_class=ovr, logisticregression__penalty=l2, logisticregression__solver=sag \n",
      "[CV]  logisticregression__multi_class=ovr, logisticregression__penalty=l2, logisticregression__solver=sag, total=   5.5s\n",
      "[CV] logisticregression__multi_class=ovr, logisticregression__penalty=l2, logisticregression__solver=sag \n",
      "[CV]  logisticregression__multi_class=ovr, logisticregression__penalty=l2, logisticregression__solver=sag, total=   5.8s\n",
      "[CV] logisticregression__multi_class=ovr, logisticregression__penalty=l2, logisticregression__solver=sag \n",
      "[CV]  logisticregression__multi_class=ovr, logisticregression__penalty=l2, logisticregression__solver=sag, total=   6.1s\n",
      "[CV] logisticregression__multi_class=ovr, logisticregression__penalty=l2, logisticregression__solver=sag \n",
      "[CV]  logisticregression__multi_class=ovr, logisticregression__penalty=l2, logisticregression__solver=sag, total=   5.7s\n",
      "[CV] logisticregression__multi_class=multinomial, logisticregression__penalty=l2, logisticregression__solver=lbfgs \n",
      "[CV]  logisticregression__multi_class=multinomial, logisticregression__penalty=l2, logisticregression__solver=lbfgs, total=  11.3s\n",
      "[CV] logisticregression__multi_class=multinomial, logisticregression__penalty=l2, logisticregression__solver=lbfgs \n",
      "[CV]  logisticregression__multi_class=multinomial, logisticregression__penalty=l2, logisticregression__solver=lbfgs, total=   9.6s\n",
      "[CV] logisticregression__multi_class=multinomial, logisticregression__penalty=l2, logisticregression__solver=lbfgs \n",
      "[CV]  logisticregression__multi_class=multinomial, logisticregression__penalty=l2, logisticregression__solver=lbfgs, total=   8.8s\n",
      "[CV] logisticregression__multi_class=multinomial, logisticregression__penalty=l2, logisticregression__solver=lbfgs \n",
      "[CV]  logisticregression__multi_class=multinomial, logisticregression__penalty=l2, logisticregression__solver=lbfgs, total=  10.3s\n",
      "[CV] logisticregression__multi_class=multinomial, logisticregression__penalty=l2, logisticregression__solver=lbfgs \n",
      "[CV]  logisticregression__multi_class=multinomial, logisticregression__penalty=l2, logisticregression__solver=lbfgs, total=   9.1s\n",
      "[CV] logisticregression__multi_class=multinomial, logisticregression__penalty=l2, logisticregression__solver=newton-cg \n",
      "[CV]  logisticregression__multi_class=multinomial, logisticregression__penalty=l2, logisticregression__solver=newton-cg, total=   8.0s\n",
      "[CV] logisticregression__multi_class=multinomial, logisticregression__penalty=l2, logisticregression__solver=newton-cg \n",
      "[CV]  logisticregression__multi_class=multinomial, logisticregression__penalty=l2, logisticregression__solver=newton-cg, total=   8.7s\n",
      "[CV] logisticregression__multi_class=multinomial, logisticregression__penalty=l2, logisticregression__solver=newton-cg \n",
      "[CV]  logisticregression__multi_class=multinomial, logisticregression__penalty=l2, logisticregression__solver=newton-cg, total=   9.0s\n",
      "[CV] logisticregression__multi_class=multinomial, logisticregression__penalty=l2, logisticregression__solver=newton-cg \n",
      "[CV]  logisticregression__multi_class=multinomial, logisticregression__penalty=l2, logisticregression__solver=newton-cg, total=   9.6s\n",
      "[CV] logisticregression__multi_class=multinomial, logisticregression__penalty=l2, logisticregression__solver=newton-cg \n",
      "[CV]  logisticregression__multi_class=multinomial, logisticregression__penalty=l2, logisticregression__solver=newton-cg, total=   8.4s\n",
      "[CV] logisticregression__multi_class=multinomial, logisticregression__penalty=l2, logisticregression__solver=sag \n",
      "[CV]  logisticregression__multi_class=multinomial, logisticregression__penalty=l2, logisticregression__solver=sag, total=   6.2s\n",
      "[CV] logisticregression__multi_class=multinomial, logisticregression__penalty=l2, logisticregression__solver=sag \n",
      "[CV]  logisticregression__multi_class=multinomial, logisticregression__penalty=l2, logisticregression__solver=sag, total=   4.3s\n",
      "[CV] logisticregression__multi_class=multinomial, logisticregression__penalty=l2, logisticregression__solver=sag \n",
      "[CV]  logisticregression__multi_class=multinomial, logisticregression__penalty=l2, logisticregression__solver=sag, total=   4.0s\n",
      "[CV] logisticregression__multi_class=multinomial, logisticregression__penalty=l2, logisticregression__solver=sag \n",
      "[CV]  logisticregression__multi_class=multinomial, logisticregression__penalty=l2, logisticregression__solver=sag, total=   4.5s\n",
      "[CV] logisticregression__multi_class=multinomial, logisticregression__penalty=l2, logisticregression__solver=sag \n",
      "[CV]  logisticregression__multi_class=multinomial, logisticregression__penalty=l2, logisticregression__solver=sag, total=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  4.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: \n",
      "0.784 (+/-0.012) for {'logisticregression__multi_class': 'multinomial', 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'lbfgs'}\n",
      "\n",
      "Grid: \n",
      "0.782 (+/-0.010) for {'logisticregression__multi_class': 'ovr', 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'lbfgs'}\n",
      "0.782 (+/-0.010) for {'logisticregression__multi_class': 'ovr', 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'newton-cg'}\n",
      "0.782 (+/-0.010) for {'logisticregression__multi_class': 'ovr', 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'sag'}\n",
      "0.784 (+/-0.012) for {'logisticregression__multi_class': 'multinomial', 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'lbfgs'}\n",
      "0.784 (+/-0.011) for {'logisticregression__multi_class': 'multinomial', 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'newton-cg'}\n",
      "0.784 (+/-0.011) for {'logisticregression__multi_class': 'multinomial', 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'sag'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'logisticregression__multi_class': 'multinomial',\n",
       " 'logisticregression__penalty': 'l2',\n",
       " 'logisticregression__solver': 'lbfgs'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2mod = make_pipeline(TfidfVectorizer(stop_words='english', ngram_range=(2, 3), analyzer='char'), LogisticRegression())\n",
    "gridSearchCV(clf2mod, parameters2, train_data_middle_segment, train_labels_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV] logisticregression__C=0.1 .......................................\n",
      "[CV] ........................ logisticregression__C=0.1, total=   5.2s\n",
      "[CV] logisticregression__C=0.1 .......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    7.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........................ logisticregression__C=0.1, total=   6.7s\n",
      "[CV] logisticregression__C=0.1 .......................................\n",
      "[CV] ........................ logisticregression__C=0.1, total=   6.5s\n",
      "[CV] logisticregression__C=0.1 .......................................\n",
      "[CV] ........................ logisticregression__C=0.1, total=   7.2s\n",
      "[CV] logisticregression__C=0.1 .......................................\n",
      "[CV] ........................ logisticregression__C=0.1, total=   6.5s\n",
      "[CV] logisticregression__C=1 .........................................\n",
      "[CV] .......................... logisticregression__C=1, total=  10.5s\n",
      "[CV] logisticregression__C=1 .........................................\n",
      "[CV] .......................... logisticregression__C=1, total=  12.2s\n",
      "[CV] logisticregression__C=1 .........................................\n",
      "[CV] .......................... logisticregression__C=1, total=  10.8s\n",
      "[CV] logisticregression__C=1 .........................................\n",
      "[CV] .......................... logisticregression__C=1, total=  11.3s\n",
      "[CV] logisticregression__C=1 .........................................\n",
      "[CV] .......................... logisticregression__C=1, total=   8.4s\n",
      "[CV] logisticregression__C=10 ........................................\n",
      "[CV] ......................... logisticregression__C=10, total=   8.1s\n",
      "[CV] logisticregression__C=10 ........................................\n",
      "[CV] ......................... logisticregression__C=10, total=   8.8s\n",
      "[CV] logisticregression__C=10 ........................................\n",
      "[CV] ......................... logisticregression__C=10, total=   9.1s\n",
      "[CV] logisticregression__C=10 ........................................\n",
      "[CV] ......................... logisticregression__C=10, total=   8.1s\n",
      "[CV] logisticregression__C=10 ........................................\n",
      "[CV] ......................... logisticregression__C=10, total=   9.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:  2.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: \n",
      "0.784 (+/-0.012) for {'logisticregression__C': 1}\n",
      "\n",
      "Grid: \n",
      "0.748 (+/-0.016) for {'logisticregression__C': 0.1}\n",
      "0.784 (+/-0.012) for {'logisticregression__C': 1}\n",
      "0.781 (+/-0.026) for {'logisticregression__C': 10}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'logisticregression__C': 1}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters4 = {\n",
    "    'logisticregression__C': [0.1, 1, 10],\n",
    "}\n",
    "clf2mod = make_pipeline(TfidfVectorizer(stop_words='english', ngram_range=(2, 3), analyzer='char'), \n",
    "                        LogisticRegression(multi_class='multinomial', solver='lbfgs'))\n",
    "gridSearchCV(clf2mod, parameters4, train_data_middle_segment, train_labels_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relation              precision     recall    f-score    support\n",
      "------------------    ---------  ---------  ---------  ---------\n",
      "NO_REL                    0.615      0.735      0.636       2300\n",
      "author                    0.884      0.862      0.879       2653\n",
      "capital                   0.870      0.643      0.812        510\n",
      "has_spouse                0.861      0.854      0.860       3019\n",
      "worked_at                 0.791      0.637      0.754       1178\n",
      "------------------    ---------  ---------  ---------  ---------\n",
      "macro-average             0.804      0.746      0.788       9660\n",
      "Average: 0.788008\n",
      "\n",
      "Cross-validation scores (StratifiedKFold):  [0.77130256 0.78812138 0.8176673  0.78067575 0.78227256]\n",
      "Mean cv score (StratifiedKFold):  0.7880079089463325\n"
     ]
    }
   ],
   "source": [
    "# This classifier uses more optimal parameters and is able to get marginally better results\n",
    "clf2mod = make_pipeline(TfidfVectorizer(stop_words='english', ngram_range=(2, 3), analyzer='char'), \n",
    "                        LogisticRegression(C=1, multi_class='multinomial', solver='lbfgs'))\n",
    "useClassifier(clf2mod, le, train_data_middle_segment, train_labels_onehot, test_data_middle_segment, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relation              precision     recall    f-score    support\n",
      "------------------    ---------  ---------  ---------  ---------\n",
      "NO_REL                    0.656      0.780      0.677       2300\n",
      "author                    0.836      0.826      0.834       2653\n",
      "capital                   0.932      0.657      0.859        510\n",
      "has_spouse                0.893      0.909      0.896       3019\n",
      "worked_at                 0.790      0.587      0.739       1178\n",
      "------------------    ---------  ---------  ---------  ---------\n",
      "macro-average             0.822      0.751      0.801       9660\n",
      "Average: 0.801213\n",
      "\n",
      "Cross-validation scores (StratifiedKFold):  [0.79292147 0.80051931 0.8116933  0.80162961 0.79930227]\n",
      "Mean cv score (StratifiedKFold):  0.801213192485917\n"
     ]
    }
   ],
   "source": [
    "clf = make_pipeline(CountVectorizer(ngram_range=(1, 2)), LogisticRegression(multi_class='ovr', solver='lbfgs'))\n",
    "useClassifier(clf, le, train_data_all_segments, train_labels_onehot, test_data_all_segments, True, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top features used to predict: \n",
      "(5, 772654)\n",
      "\n",
      "Class NO_REL best: \n",
      "(0.6592857822275802, 'india')\n",
      "(0.6751229576087763, 'stars')\n",
      "(0.7125847509006051, 'bill')\n",
      "\n",
      "Class author best: \n",
      "(1.1773082744019743, 'books')\n",
      "(1.7301629307234392, 'book')\n",
      "(2.3289587019069633, 'novel')\n",
      "\n",
      "Class capital best: \n",
      "(0.7251712587666335, 'airport')\n",
      "(1.1386176456328614, 'capital of')\n",
      "(1.3739590687226302, 'capital')\n",
      "\n",
      "Class has_spouse best: \n",
      "(1.9053646128553086, 'married')\n",
      "(2.16041766314762, 'husband')\n",
      "(2.9616921783107704, 'wife')\n",
      "\n",
      "Class worked_at best: \n",
      "(1.2986412437578314, 'ceo')\n",
      "(1.3954142887266279, 'founder')\n",
      "(2.1071297174143093, 'professor')\n"
     ]
    }
   ],
   "source": [
    "print(\"Top features used to predict: \")\n",
    "#printNMostInformative(clf, le, 3, 'dictvectorizer')\n",
    "printNMostInformative(clf, le, 3, 'countvectorizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot_coefficients(clf2mod, 'countvectorizer', le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relation              precision     recall    f-score    support\n",
      "------------------    ---------  ---------  ---------  ---------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-70aa5994e002>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_pipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCountVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mngram_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmulti_class\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ovr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'lbfgs'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0museClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_data_all_segments\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels_onehot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data_all_segments\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-38b9864f5577>\u001b[0m in \u001b[0;36museClassifier\u001b[1;34m(clf, encoder, train_features, train_labels, test_features, do_check, filename)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0museClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdo_check\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mavg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluateCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Average: %f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mavg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\MEGA\\Uni\\7 Semester MA\\Techniken der Semantikanalyse\\Programming\\4\\pa4_functions.py\u001b[0m in \u001b[0;36mevaluateCV\u001b[1;34m(classifier, label_encoder, X, y, verbose)\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m             \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m             \u001b[0mpred_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m             \u001b[0mstats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    246\u001b[0m             \u001b[0mThis\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m         \"\"\"\n\u001b[1;32m--> 248\u001b[1;33m         \u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    249\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    211\u001b[0m                 Xt, fitted_transformer = fit_transform_one_cached(\n\u001b[0;32m    212\u001b[0m                     \u001b[0mcloned_transformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m                     **fit_params_steps[name])\n\u001b[0m\u001b[0;32m    214\u001b[0m                 \u001b[1;31m# Replace the transformer of the step with the fitted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m                 \u001b[1;31m# transformer. This is necessary when loading the transformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\memory.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, weight, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    579\u001b[0m                        **fit_params):\n\u001b[0;32m    580\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit_transform'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 581\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    582\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[1;32m--> 869\u001b[1;33m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[0;32m    870\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    871\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m    812\u001b[0m                                  \" contain stop words\")\n\u001b[0;32m    813\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 814\u001b[1;33m         \u001b[0mj_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj_indices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    815\u001b[0m         \u001b[0mindptr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrombuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindptr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrombuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clf = make_pipeline(CountVectorizer(ngram_range=(1, 3)), LogisticRegression(multi_class='ovr', solver='lbfgs'))\n",
    "useClassifier(clf, le, train_data_all_segments, train_labels_onehot, test_data_all_segments, True, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with Word2Vec vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "# at the moment, this function checks each word in the input array and replaces it with the mean of the w2v vector\n",
    "def w2v_transform(input_array): # input can e.g. be all middle segments\n",
    "    # the word2vec vectors can be downloaded from(1.5GB): \n",
    "    # https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit\n",
    "    word_vectors = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n",
    "    \n",
    "    unique_word_matrix = []\n",
    "    for item in input_array:\n",
    "        unique_word_matrix.append(list(set(item.lower().split())))\n",
    "    # sentences that contain more or less than 120 words are either cut off or filled up with zeros\n",
    "    mean_matrix = np.zeros((len(unique_word_matrix), 120))\n",
    "    i = 0; \n",
    "    while i < len(unique_word_matrix):\n",
    "        set_matrix = []\n",
    "        j = 0;\n",
    "        while j < 120:\n",
    "            if j >= len(unique_word_matrix[i]):\n",
    "                mean_matrix[i][j] = 0\n",
    "                j += 1\n",
    "                continue;\n",
    "            word = unique_word_matrix[i][j]\n",
    "            if word in word_vectors.vocab:\n",
    "                mean_matrix[i, j] = np.mean(word_vectors[word])\n",
    "            else:\n",
    "                mean_matrix[i][j] = 0\n",
    "            j += 1\n",
    "        i += 1\n",
    "    return mean_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = w2v_transform(train_data_middle_segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-validation scores (StratifiedKFold):  [0.08572679 0.10160061 0.09606363 0.10468581 0.08435447]\n",
      "Mean cv score (StratifiedKFold):  0.09448625989628309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "evaluateCV_check(LogisticRegression(), mean_matrix, train_labels_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
